{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cover Letter Generator\n",
    "\n",
    "In today's competitive job market, submitting your resume often just isn't enough to make you stand out. Many companies now require a cover letter, but when you are applying to several jobs at once, writing an individual cover letter for each position can be time consuming. This project will solve this problem by creating a cover letter generator. \n",
    "\n",
    "The original goal was to use user information about the job listing and their experience extracted from a resume to create a unique cover letter for each job. Due to lack of training data, this generator can only generate generic cover letters with tokens that the user can fill in themselves.\n",
    "\n",
    "Further work on this project is needed to accomplish the original goal, specifically more training data (sample cover letters) are needed. Despite not accomplishing the original goal, this model could still be useful by giving the user a starting point when writing cover letters if more training data was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will define a function to checkout some of the corpus statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_stats(corpus):\n",
    "  print('Corpus Stats:')\n",
    "  print('Number of Documents: ' + str(len(corpus.fileids())))\n",
    "  print('Number of Paragraphs ' + str(len(corpus.paras())))\n",
    "  print('Number of sentences: ' + str(len(corpus.sents())))\n",
    "  print('Number of words: ' + str(len(corpus.words())))\n",
    "  print(\"Vocabulary: \" + str(len(set(w.lower() for w in corpus.words()))))\n",
    "  print(\"Avg chars per word: \" + str(round(len(corpus.raw())/len(corpus.words()),1)))\n",
    "  print(\"Avg words per sentence: \" + str(round(len(corpus.words())/len(corpus.sents()),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sample cover letter .txt files via NLTK's PlaintextCorpusReader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './cover_letter_samples'\n",
    "doc_pattern = r'.*\\.txt'\n",
    "corpus = PlaintextCorpusReader(path, doc_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Stats:\n",
      "Number of Documents: 51\n",
      "Number of Paragraphs 246\n",
      "Number of sentences: 625\n",
      "Number of words: 14942\n",
      "Vocabulary: 2564\n",
      "Avg chars per word: 5.6\n",
      "Avg words per sentence: 23.9\n"
     ]
    }
   ],
   "source": [
    "corpus_stats(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [corpus.raw(fileid) for fileid in corpus.fileids()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc.replace('\\n', '') for doc in docs]\n",
    "docs = [doc.replace('\\r', '') for doc in docs]\n",
    "docs = [doc.replace(')', '') for doc in docs]\n",
    "docs = [doc.replace('(', '') for doc in docs]\n",
    "docs = [doc.replace(',', '') for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc.lower() for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of individual words for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [word_tokenize(doc) for doc in docs]\n",
    "\n",
    "lens = [len(token) for token in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a single list of all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = []\n",
    "for token in tokenized:\n",
    "    tokens_list.extend(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will encode the text to numeric vectors using BERT encoder because it is pre-trained and can understand the meaning of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tz = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tz.encode_plus(\n",
    "    text=tokens_list,  # the text to be encoded\n",
    "    add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "    max_length = len(tokens_list),  # maximum length of a document\n",
    "    truncation = True,\n",
    "    padding = 'max_length',  # Add [PAD]s\n",
    "    return_attention_mask = True,  # Generate the attention mask\n",
    "    return_tensors = 'tf',  # ask the function to return TensorFlow tensors\n",
    ")\n",
    "input_ids = encoded['input_ids']\n",
    "attn_mask = encoded['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT encoder outputs a list of lists, so I will consolidate them into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_list = []\n",
    "for input_id in input_ids:\n",
    "    input_ids_list.extend(input_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BERT encoder also outputs tensors, I need to convert them to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_int = []\n",
    "\n",
    "for tensor in input_ids_list:\n",
    "    input_ids_int.append(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the words are numeric vectors, I will need to be able to decode the model's output. I will also need to be able to encode a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {input_ids_int[i]: tokens_list[i] for i in range(len(input_ids_int))}\n",
    "word_to_id = {tokens_list[i]: input_ids_int[i] for i in range(len(tokens_list))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are modeling sequence-to-sequence, I will create sequences and the word that immediately follows that sequence to use as \"labels.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(input_ids_list) - seq_len, 1):\n",
    "    in_seq = input_ids_list[i:i+seq_len]\n",
    "    out_seq = input_ids_list[i + seq_len]\n",
    "    X.append(in_seq)\n",
    "    y.append(out_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the input to (*time steps*, *batch size*, *something else*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.reshape(X, (len(X), seq_len, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_array = np_utils.to_categorical(y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28067, 13412)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X_array.shape[1], X_array.shape[2]), return_sequences=True))\n",
    "model.add(Dense(256))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dense(128))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(y_array.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using ModelCheckpoint to save the model weights, so I don't have to retrain the model every time I restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 27s 520ms/step - loss: 12.6948 - val_loss: 0.7272\n",
      "\n",
      "Epoch 00001: loss improved from inf to 11.25634, saving model to model_weights_saved.hdf5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 20s 476ms/step - loss: 11.7062 - val_loss: 0.7276\n",
      "\n",
      "Epoch 00002: loss did not improve from 11.25634\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 22s 521ms/step - loss: 9.3179 - val_loss: 0.7321\n",
      "\n",
      "Epoch 00003: loss did not improve from 11.25634\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 22s 518ms/step - loss: 11.9221 - val_loss: 0.7611\n",
      "\n",
      "Epoch 00004: loss did not improve from 11.25634\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 22s 517ms/step - loss: 12.6896 - val_loss: 0.7734\n",
      "\n",
      "Epoch 00005: loss did not improve from 11.25634\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 21s 495ms/step - loss: 14.0080 - val_loss: 0.7920\n",
      "\n",
      "Epoch 00006: loss did not improve from 11.25634\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 21s 497ms/step - loss: 11.7724 - val_loss: 0.8063\n",
      "\n",
      "Epoch 00007: loss did not improve from 11.25634\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 21s 494ms/step - loss: 13.1537 - val_loss: 0.8291\n",
      "\n",
      "Epoch 00008: loss did not improve from 11.25634\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 9.1622 - val_loss: 0.8331\n",
      "\n",
      "Epoch 00009: loss did not improve from 11.25634\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 13.2400 - val_loss: 0.8627\n",
      "\n",
      "Epoch 00010: loss did not improve from 11.25634\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 22s 519ms/step - loss: 9.5836 - val_loss: 0.8767\n",
      "\n",
      "Epoch 00011: loss did not improve from 11.25634\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 22s 514ms/step - loss: 9.3762 - val_loss: 0.9008\n",
      "\n",
      "Epoch 00012: loss did not improve from 11.25634\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 21s 506ms/step - loss: 10.9936 - val_loss: 0.9070\n",
      "\n",
      "Epoch 00013: loss did not improve from 11.25634\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 21s 494ms/step - loss: 16.2520 - val_loss: 0.9046\n",
      "\n",
      "Epoch 00014: loss did not improve from 11.25634\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 13.8688 - val_loss: 0.9281\n",
      "\n",
      "Epoch 00015: loss did not improve from 11.25634\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 21s 498ms/step - loss: 11.3523 - val_loss: 0.9457\n",
      "\n",
      "Epoch 00016: loss did not improve from 11.25634\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 11.7694 - val_loss: 0.9657\n",
      "\n",
      "Epoch 00017: loss did not improve from 11.25634\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 10.7140 - val_loss: 0.9824\n",
      "\n",
      "Epoch 00018: loss did not improve from 11.25634\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 23s 548ms/step - loss: 11.7169 - val_loss: 1.0034\n",
      "\n",
      "Epoch 00019: loss did not improve from 11.25634\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 21s 508ms/step - loss: 13.1485 - val_loss: 0.9509\n",
      "\n",
      "Epoch 00020: loss did not improve from 11.25634\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_array, y_array, validation_split = 0.2, epochs=20, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is underfit, evidenced by the high test loss that doesn't converge. More training data might solve this problem. Because of the underfitting, the model will likely not output good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to test the model. I input the beginning of a cover letter. The loop deletes the first token in the sample, predicts on a sequence of the specified length, append the predicted word to the end of the sample. The first word is dropped and the model predicts on the next sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am excited to apply for your company because i the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "sample = \"I am excited to apply for your company because I\"\n",
    "sample = sample.lower()\n",
    "sample_split = word_tokenize(sample)\n",
    "sample_split.insert(0, 0)\n",
    "\n",
    "for i in range(25):\n",
    "    sample_split = sample_split[1:]\n",
    "\n",
    "    sample_ids = [word_to_id[word] for word in sample_split]\n",
    "\n",
    "    sample_array = tf.convert_to_tensor(sample_ids)\n",
    "    sample_array = [list(sample_array)]\n",
    "    sample_array = np.reshape(sample_array, (1, seq_len, 1))\n",
    "    prediction = model.predict(sample_array)\n",
    "\n",
    "\n",
    "    pred_index = prediction[0].argmax()\n",
    "    new_word = tokens_list[pred_index]\n",
    "    sample_split.append(new_word)\n",
    "    sample = sample + ' ' + new_word\n",
    "\n",
    "sample = sample.capitalize()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(LSTM(256, input_shape=(X_array.shape[1], X_array.shape[2]), return_sequences=True))\n",
    "model_2.add(Dense(256, activation = 'relu'))\n",
    "model_2.add(LSTM(128, return_sequences = True))\n",
    "model_2.add(Dense(128, activation = 'relu'))\n",
    "model_2.add(LSTM(256, return_sequences = True))\n",
    "model_2.add(Dense(y_array.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 27s 519ms/step - loss: 13.0437 - val_loss: 0.7456\n",
      "\n",
      "Epoch 00001: loss did not improve from 11.25634\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 19s 453ms/step - loss: 10.3689 - val_loss: 0.7231\n",
      "\n",
      "Epoch 00002: loss did not improve from 11.25634\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 19s 451ms/step - loss: 9.4916 - val_loss: 0.7606\n",
      "\n",
      "Epoch 00003: loss did not improve from 11.25634\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 19s 454ms/step - loss: 10.1956 - val_loss: 0.7826\n",
      "\n",
      "Epoch 00004: loss did not improve from 11.25634\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 19s 465ms/step - loss: 12.3464 - val_loss: 0.8046\n",
      "\n",
      "Epoch 00005: loss did not improve from 11.25634\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 19s 452ms/step - loss: 11.0861 - val_loss: 0.8408\n",
      "\n",
      "Epoch 00006: loss did not improve from 11.25634\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 19s 454ms/step - loss: 11.9074 - val_loss: 0.8321\n",
      "\n",
      "Epoch 00007: loss did not improve from 11.25634\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 19s 454ms/step - loss: 10.6146 - val_loss: 0.8736\n",
      "\n",
      "Epoch 00008: loss did not improve from 11.25634\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 19s 453ms/step - loss: 10.7341 - val_loss: 0.8854\n",
      "\n",
      "Epoch 00009: loss did not improve from 11.25634\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 19s 462ms/step - loss: 8.3658 - val_loss: 0.8977\n",
      "\n",
      "Epoch 00010: loss did not improve from 11.25634\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 22s 535ms/step - loss: 12.7462 - val_loss: 0.8394\n",
      "\n",
      "Epoch 00011: loss did not improve from 11.25634\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 21s 511ms/step - loss: 13.2133 - val_loss: 0.7805\n",
      "\n",
      "Epoch 00012: loss did not improve from 11.25634\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 23s 537ms/step - loss: 11.2318 - val_loss: 0.9900\n",
      "\n",
      "Epoch 00013: loss did not improve from 11.25634\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 22s 519ms/step - loss: 13.7515 - val_loss: 0.9286\n",
      "\n",
      "Epoch 00014: loss did not improve from 11.25634\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 23s 555ms/step - loss: 16.4210 - val_loss: 0.9935\n",
      "\n",
      "Epoch 00015: loss did not improve from 11.25634\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 24s 564ms/step - loss: 12.2412 - val_loss: 0.8064\n",
      "\n",
      "Epoch 00016: loss improved from 11.25634 to 11.22443, saving model to model_weights_saved.hdf5\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 24s 583ms/step - loss: 10.3011 - val_loss: 0.9798\n",
      "\n",
      "Epoch 00017: loss improved from 11.22443 to 11.07594, saving model to model_weights_saved.hdf5\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 8.7899 - val_loss: 0.9434\n",
      "\n",
      "Epoch 00018: loss improved from 11.07594 to 10.76900, saving model to model_weights_saved.hdf5\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 8.9295 - val_loss: 1.0182\n",
      "\n",
      "Epoch 00019: loss improved from 10.76900 to 10.40538, saving model to model_weights_saved.hdf5\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 21s 503ms/step - loss: 11.6276 - val_loss: 1.0259\n",
      "\n",
      "Epoch 00020: loss improved from 10.40538 to 10.13246, saving model to model_weights_saved.hdf5\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(X_array, y_array, validation_split = 0.2, epochs=20, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_2.history['loss'])\n",
    "plt.plot(history_2.history['val_loss'])\n",
    "plt.title('Model Loss - relu activation')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am excited to apply for your company because i my i research learning disputes small building interpersonal in career the including including career remarks remarks remarks remarks remarks remarks remarks remarks remarks remarks remarks\n"
     ]
    }
   ],
   "source": [
    "sample = \"I am excited to apply for your company because I\"\n",
    "sample = sample.lower()\n",
    "sample_split = word_tokenize(sample)\n",
    "sample_split.insert(0, 0)\n",
    "\n",
    "for i in range(25):\n",
    "    sample_split = sample_split[1:]\n",
    "\n",
    "    sample_ids = [word_to_id[word] for word in sample_split]\n",
    "\n",
    "    sample_array = tf.convert_to_tensor(sample_ids)\n",
    "    sample_array = [list(sample_array)]\n",
    "    sample_array = np.reshape(sample_array, (1, seq_len, 1))\n",
    "    prediction = model.predict(sample_array)\n",
    "\n",
    "\n",
    "    pred_index = prediction[0].argmax()\n",
    "    new_word = tokens_list[pred_index]\n",
    "    sample_split.append(new_word)\n",
    "    sample = sample + ' ' + new_word\n",
    "\n",
    "sample = sample.capitalize()\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of both of these models is English text, but it does not make sense. The first model simply predicts the word that appears immediately before it. The loss of the second model doesn't seem improve until about the 12th epoch. Since both models have an underfitting problem, the results could probably be improved by more training data. Neural nets require large training sets, and my corpus only contains 51 cover letter samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
